{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries in dictionary style\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import MySQLdb\n",
    "\n",
    "libraries = {'numpy': np, 'pandas': pd, 'datetime': datetime}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database credentials\n",
    "dsn_database = \"ercm_kc135\"\n",
    "dsn_hostname = \"localhost\"\n",
    "dsn_port = 3306\n",
    "dsn_uid = \"root\"\n",
    "dsn_pwd = \"root\"\n",
    "\n",
    "# create the database connection\n",
    "conn = MySQLdb.connect(host = dsn_hostname, port = dsn_port, user = dsn_uid, passwd = dsn_pwd, db = dsn_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dataframe\n",
    "df = []\n",
    "\n",
    "# select last five years of sortie history\n",
    "query = \"SELECT * FROM ercm_kc135.compiled_sortie_history_data\"\n",
    "\n",
    "# create dataframe from sortie history\n",
    "df = pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the period (will make this a parameter eventually)\n",
    "period = 3\n",
    "date_selection = 'Last_Record'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_data_set(df, dselect, libraries):\n",
    "    \"\"\" Limits the data set to only necessary columns and only relevant dates\n",
    "    Args:\n",
    "        df: dateframe from previous function\n",
    "        dselect: determines what will set the current date\n",
    "        libraries: dictionary of libraries; access by name\n",
    "        e.g. pd = libraries['pandas'] or stats = libraries['scipy']['stats']\n",
    "    Returns:\n",
    "        df: data frame with limited data\n",
    "    \"\"\"\n",
    "    dt = libraries['datetime']\n",
    "\n",
    "    # limit the data frame to desired columns and the last three years\n",
    "    df = df[['Serial_Number', 'Depart_Date', 'Flying_Hours']]\n",
    "\n",
    "    if dselect == 'Today':\n",
    "        ldate = dt.datetime.now().year - 5\n",
    "    else:\n",
    "        ldate = df['Depart_Date'].dt.year.max() - 5\n",
    "\n",
    "    # limit the data frame\n",
    "    df = df[df['Depart_Date'].dt.year >= ldate]\n",
    "\n",
    "    # calculate the first of the month\n",
    "    df['Fixed_Date'] = pd.to_datetime(df['Depart_Date']).apply(lambda x: '{year}-{month}-01'.format(year=x.year, month=x.month) if x.month > 9 else '{year}-0{month}-01'.format(year=x.year, month=x.month))\n",
    "    df['Fixed_Date'] = df['Fixed_Date'].map(lambda x: np.datetime64(x))\n",
    "    \n",
    "\n",
    "    return df, ldate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, last_date = limit_data_set(df, date_selection, libraries)\n",
    "# print df.head(200)\n",
    "# print df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_monthly_values(df, libraries):\n",
    "    \"\"\" Calculates the number of unique tail numbers present in each time window.\n",
    "    Args:\n",
    "        df: date frame from previous function\n",
    "        libraries: dictionary of libraries; access by name\n",
    "    Returns:\n",
    "        tailcount: count of unique tail_numbers in each window\n",
    "    \"\"\"\n",
    "    pd = libraries['pandas']\n",
    "    \n",
    "    # subset values to only be necessary columns\n",
    "    df = df[['Serial_Number','Flying_Hours', 'Fixed_Date']]\n",
    "\n",
    "    #group by month and count distinct tails\n",
    "    totals = df.groupby(['Fixed_Date'], as_index=False).agg({'Serial_Number': pd.Series.nunique, 'Flying_Hours': pd.Series.sum}) \n",
    "    \n",
    "    # rename the columns\n",
    "    totals.rename(columns={'Serial_Number': 'Unique_Tail_Count', 'Flying_Hours': 'Total_Flying_Hours'}, inplace=True)\n",
    "    \n",
    "    # calculate the monthly average\n",
    "    totals['Monthly_Average'] = totals['Total_Flying_Hours'] / totals['Unique_Tail_Count']\n",
    "    \n",
    "    # convert to data frame\n",
    "    totals = pd.DataFrame(totals)\n",
    "    \n",
    "    # drop intermediate columns\n",
    "    totals.drop(['Unique_Tail_Count', 'Total_Flying_Hours'], axis=1, inplace = True)\n",
    "    \n",
    "    return totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fixed_Date  Monthly_Average\n",
      "0 2013-01-01        36.813684\n",
      "1 2013-02-01        36.553425\n",
      "2 2013-03-01        35.246900\n",
      "3 2013-04-01        36.233947\n",
      "4 2013-05-01        37.288283\n",
      "Fixed_Date         datetime64[ns]\n",
      "Monthly_Average           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "totals = calc_monthly_values(df, libraries)\n",
    "# print totals.head()\n",
    "# print totals.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_windows(df, p, libraries):\n",
    "    \"\"\" Calculates window value columns to determine what periods a flight record could be grouped into.\n",
    "    Example: '2016-01-04' would return window values '2015-11-01', '2015-12-01', '2016-01-01'.\n",
    "    Args:\n",
    "        df: date frame from previous function\n",
    "        p: currently only works where period = 3. Long-term, will try and make dynamic based on this value\n",
    "        libraries: dictionary of libraries; access by name\n",
    "        e.g. pd = libraries['pandas'] or stats = libraries['scipy']['stats']\n",
    "    Returns:\n",
    "        windowed: dataframe with window values where record is active\n",
    "    \"\"\"\n",
    "    np = libraries['numpy']\n",
    "\n",
    "    # create useful window columns by iterating for 1 through number of periods specified\n",
    "    for i in range(1, p + 1):\n",
    "        # create column name and set window value (either 2, 1, or 0 when period = 3)\n",
    "        column = 'W' + str(i)\n",
    "        window = p - i\n",
    "\n",
    "        # extract baseline month values\n",
    "        df['Month'] = df['Fixed_Date'].dt.month\n",
    "        df['Year'] = df['Fixed_Date'].dt.year\n",
    "\n",
    "        # subset with loc to fix problematic time periods with year overlaps\n",
    "        # if window is 2 and month is Jan or Feb, fix date accordingly\n",
    "        if window == 2:\n",
    "            df.loc[(df.Month == 1) | (df.Month == 2), 'Year'] = df.Year - 1\n",
    "            df.loc[(df.Month == 2), 'Month'] = 14\n",
    "            df.loc[(df.Month == 1), 'Month'] = 13\n",
    "        # if window is 1 and month is Jan, fix date accordingly\n",
    "        elif window == 1:\n",
    "            df.loc[(df.Month == 1), 'Year'] = df.Year - 1\n",
    "            df.loc[(df.Month == 1), 'Month'] = 13\n",
    "\n",
    "        # Decrement them month value based on the window value\n",
    "        df['Month'] = df.Month - window\n",
    "\n",
    "        # clean up date integer values by adding appropriate 0's and converting to strings\n",
    "        df.loc[df.Month < 10, 'Month'] = '0' + df['Month'].astype(str)  # add 0's to single digit months\n",
    "        df.loc[df.Month >= 10, 'Month'] = df['Month'].astype(str)  # do not add 0's to double digit months\n",
    "        df['Year'] = df['Year'].astype(str)\n",
    "\n",
    "        # create the value for each window as a string\n",
    "        df[column] = df['Year'] + '-' + df['Month'] + '-01'\n",
    "\n",
    "        # convert each window back to original datetime64 format\n",
    "        df[column] = df[column].map(lambda x: np.datetime64(x))\n",
    "\n",
    "    # drop the month and year columns\n",
    "    windowed = df.drop(['Month', 'Year'], axis=1)\n",
    "\n",
    "    return windowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_rolling_avg(df, last_date, p, libraries):\n",
    "    \"\"\" Calculates the rolling average by melting the window columns and grouping the result.\n",
    "    Args:\n",
    "     df: date frame from previous function\n",
    "     tailcount: count of unique tails active in each month\n",
    "     last_date: year associated with five years ago\n",
    "     p: currently only works where period = 3. Long-term, will try and make dynamic based on this value\n",
    "     libraries: dictionary of libraries; access by name\n",
    "        e.g. pd = libraries['pandas'] or stats = libraries['scipy']['stats']\n",
    "    Returns:\n",
    "    grouped: data frame with the moving average of flying_hours\n",
    "    \"\"\"\n",
    "    pd = libraries['pandas']\n",
    "\n",
    "    # create a list of column values thus far\n",
    "    columns = list(df.columns.values)\n",
    "\n",
    "    # calculate the point at which the melted data frame with pivot\n",
    "    melt_axis = len(columns) - p\n",
    "\n",
    "    # create a melted data frame to used for group by calculation\n",
    "    melted = pd.melt(df,\n",
    "                     id_vars=columns[1:melt_axis],\n",
    "                     value_vars=columns[melt_axis:len(columns)],\n",
    "                     var_name='Window',\n",
    "                     value_name='Window_Val'\n",
    "                     )\n",
    "\n",
    "    # group by window value and calculate the mean\n",
    "    grouped = melted.groupby(['Window_Val'], as_index=False).sum()\n",
    "\n",
    "    # rename columns\n",
    "    grouped.rename(columns={'Window_Val': 'Three_Month_Start_Date', 'Monthly_Average': 'Average_Flying_Hours'}, inplace=True)\n",
    "\n",
    "    # eliminate windows that predate the start year\n",
    "    grouped = pd.DataFrame(grouped[grouped['Three_Month_Start_Date'].dt.year >= last_date])\n",
    "    \n",
    "\n",
    "    \n",
    "    # eliminate the last two windows\n",
    "    grouped.drop(grouped.tail(2).index, inplace=True)\n",
    "\n",
    "    return melted, grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Three_Month_Start_Date  Average_Flying_Hours\n",
      "2              2013-01-01            108.614009\n",
      "3              2013-02-01            108.034272\n",
      "4              2013-03-01            108.769131\n",
      "5              2013-04-01            110.208916\n",
      "6              2013-05-01            112.175247\n",
      "7              2013-06-01            116.549394\n",
      "8              2013-07-01            117.763543\n",
      "9              2013-08-01            115.581446\n",
      "10             2013-09-01            109.736812\n",
      "11             2013-10-01            106.750847\n",
      "12             2013-11-01            104.584654\n",
      "13             2013-12-01            106.754788\n",
      "14             2014-01-01            116.643897\n",
      "15             2014-02-01            125.995451\n",
      "16             2014-03-01            131.443654\n",
      "17             2014-04-01            131.341376\n",
      "18             2014-05-01            131.698112\n",
      "19             2014-06-01            134.636000\n",
      "20             2014-07-01            135.762591\n",
      "21             2014-08-01            143.810117\n",
      "22             2014-09-01            146.054095\n",
      "23             2014-10-01            146.215832\n",
      "24             2014-11-01            142.469633\n",
      "25             2014-12-01            143.907975\n",
      "26             2015-01-01            152.384894\n",
      "27             2015-02-01            157.917423\n",
      "28             2015-03-01            163.939652\n",
      "29             2015-04-01            168.325848\n",
      "30             2015-05-01            171.216685\n",
      "31             2015-06-01            172.139273\n",
      "..                    ...                   ...\n",
      "33             2015-08-01            157.168937\n",
      "34             2015-09-01            141.982867\n",
      "35             2015-10-01            135.539366\n",
      "36             2015-11-01            130.527429\n",
      "37             2015-12-01            133.517211\n",
      "38             2016-01-01            136.084155\n",
      "39             2016-02-01            141.533368\n",
      "40             2016-03-01            144.985804\n",
      "41             2016-04-01            150.594175\n",
      "42             2016-05-01            148.436925\n",
      "43             2016-06-01            151.778178\n",
      "44             2016-07-01            145.861067\n",
      "45             2016-08-01            147.451420\n",
      "46             2016-09-01            138.960739\n",
      "47             2016-10-01            135.380092\n",
      "48             2016-11-01            126.831529\n",
      "49             2016-12-01            126.880964\n",
      "50             2017-01-01            132.486710\n",
      "51             2017-02-01            138.536770\n",
      "52             2017-03-01            144.052157\n",
      "53             2017-04-01            146.875234\n",
      "54             2017-05-01            146.211618\n",
      "55             2017-06-01            146.272935\n",
      "56             2017-07-01            136.938911\n",
      "57             2017-08-01            134.370432\n",
      "58             2017-09-01            125.613406\n",
      "59             2017-10-01            121.769334\n",
      "60             2017-11-01            116.389966\n",
      "61             2017-12-01            112.401210\n",
      "62             2018-01-01            113.227776\n",
      "\n",
      "[61 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "windowed = calc_windows(totals, period, libraries)\n",
    "melted, final = calc_rolling_avg(windowed, last_date, period, libraries)\n",
    "\n",
    "# print totals.head()\n",
    "# print windowed.head()\n",
    "# print melted.head()\n",
    "print final.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
